<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lab 11 - Supervised Classification | Remote Sensing Course</title>
    <link rel="stylesheet" href="../css/style.css">
    <meta name="robots" content="index, follow">
    <meta name="description" content="Google Earth Engine lab 11: Lab 11 - Supervised Classification">
</head>
<body>
    <div class="container">
        <nav class="breadcrumb">
            <a href="../index.html">Home</a> &gt; <a href="../index.html#labs">Labs</a> &gt; Lab 11
        </nav>

        <header class="lab-header">
            <h1>Lab 11 - Supervised Classification</h1>
        </header>

        <main class="lab-content">
<p><span>Supervised classification uses a training dataset with known labels and representing the spectral characteristics of each land cover class of interest to “supervise” the classification. The overall approach of a supervised classification in Earth Engine is summarized as follows:&nbsp;</span></p>
<ol>
<li aria-level="1"><span>Get a scene.</span></li>
<li aria-level="1"><span>Collect training data.</span></li>
<li aria-level="1"><span>Select and train a classifier using the training data.</span></li>
<li aria-level="1"><span>Classify the image using the selected classifier.</span></li>
</ol>
<p><span>Let's get started</span></p>
<ol style="list-style-type: decimal;">
<li><span>We will begin by manually creating training data based on a clear Landsat image. Copy the code block below to define your Landsat 8 scene variable and add it to the map. We will use a point in Milan, Italy, as the center of the area for our image classification.</span></li>
<li>
<pre>// Create an Earth Engine Point object over Milan.<br>var pt = ee.Geometry.Point([9.453, 45.424]);<br><br>// Filter the Landsat 8 collection and select the least cloudy image.<br>var landsat = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')<br>&nbsp; &nbsp; .filterBounds(pt)<br>&nbsp; &nbsp; .filterDate('2019-01-01', '2020-01-01')<br>&nbsp; &nbsp; .sort('CLOUD_COVER')<br>&nbsp; &nbsp; .first();<br><br>// Center the map on that image.<br>Map.centerObject(landsat, 8);<br><br>// Add Landsat image to the map.<br>var visParams = {<br>&nbsp; &nbsp; bands: ['SR_B4', 'SR_B3', 'SR_B2'],<br>&nbsp; &nbsp; min: 7000,<br>&nbsp; &nbsp; max: 12000<br>};<br>Map.addLayer(landsat, visParams, 'Landsat 8 image');</pre>
<span><img src="../images/canvas/Uploaded%20Media/Screenshot%202023-03-03%20at%206.55.38%20AM.png" alt="resulting image from landsat"   loading="lazy">&nbsp;</span>
</li>
<li>
<span>Using the </span><strong>Geometry Tools</strong><span>, we will create points on the Landsat image that represent land cover classes of interest to use as our training data. We’ll need to do two things: (1) identify where each land cover occurs on the ground, and (2) label the points with the proper class number. For this exercise, we will use the classes and codes shown in Table.</span>
</li>
<li>
<p><span>Land cover classes&nbsp;</span></p>
<span><span><br></span></span>
<table>
<tbody>
<tr>
<td>
<p><strong>Class</strong></p>
</td>
<td>
<p><strong>Class code</strong></p>
</td>
</tr>
<tr>
<td>
<p><span>Forest</span></p>
</td>
<td>
<p><span>0</span></p>
</td>
</tr>
<tr>
<td>
<p><span>Developed</span></p>
</td>
<td>
<p><span>1</span></p>
</td>
</tr>
<tr>
<td>
<p><span>Water</span></p>
</td>
<td>
<p><span>2</span></p>
</td>
</tr>
<tr>
<td>
<p><span>Herbaceous</span></p>
</td>
<td>
<p><span>3</span></p>
</td>
</tr>
</tbody>
</table>
<span><br></span>
</li>
<li>
<p><span>In the </span><strong>Geometry Tools</strong><span>, click on the marker option. This will create a point geometry which will show up as an import named “geometry”. Click on the gear icon to configure this import.</span></p>
</li>
<li><span><img src="../images/canvas/Uploaded%20Media/Screenshot%202023-03-03%20at%206.57.16%20AM.png" alt="where the geomerty tool is."   loading="lazy"></span></li>
<li>
<p><span>We will start by collecting forest points, so name the import </span><span>forest</span><span>. Import it as a </span><span>FeatureCollection</span><span>, and then click </span><strong>+ Property</strong><span>. Name the new property “class” and give it a value of 0. We can also choose a color to represent this class. For a forest class, it is natural to choose a green color. You can choose the color you prefer by clicking on it, or, for more control, you can use a hexadecimal value. </span></p>
</li>
<li>
<p><span>H</span><span>exadecimal values are used throughout the digital world to represent specific colors across computers and operating systems. They are specified by six values arranged in three pairs, with one pair each for the red, green, and blue brightness values. If you’re unfamiliar with hexadecimal values, imagine for a moment that colors were specified in pairs of base 10 numbers instead of pairs of base 16. In that case, a bright pure red value would be “990000”; a bright pure green value would be “009900”; and a bright pure blue value would be “000099”. A value like “501263” would be a mixture of the three colors, not especially bright, having roughly equal amounts of blue and red, and much less green: a color that would be a shade of purple. To create numbers in the hexadecimal system, which might feel entirely natural if humans had evolved to have 16 fingers, sixteen “digits” are needed: a base 16 counter goes 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, F, then 10, 11, and so on. Given that counting framework, the number “FF” is like “99” in base 10: the largest two-digit number. The hexadecimal color used for coloring the letters of the word </span><span>FeatureCollection</span><span> in this book, a color with roughly equal amounts of blue and red, and much less green, is “7F1FA2”&nbsp;</span></p>
</li>
<li>
<p><span>Returning to the coloring of the </span><span>forest</span><span> points, the hexadecimal value “589400” is a little bit of red, about twice as much green, and no blue: the deep green. Enter that value, with or without the “#” in front, and click </span><strong>OK</strong><span> after finishing the configuration.</span></p>
</li>
<li><img src="../images/canvas/Uploaded%20Media/Screenshot%202023-03-03%20at%208.38.15%20AM.png" alt="Screenshot 2023-03-03 at 8.38.15 AM.png" loading="lazy"></li>
<li>
<p><span>Now, in the </span><strong>Geometry Imports</strong><span>, we will see that the import has been renamed </span><span>forest</span><span>. Click on it to activate the drawing mode in order to start collecting </span><span>forest</span><span> points.&nbsp;</span></p>
</li>
<li><span><img src="../images/canvas/Uploaded%20Media/Screenshot%202023-03-03%20at%207.01.23%20AM.png" alt="ready to start collecting points"   loading="lazy"></span></li>
<li>
<p><span>Now, start collecting points over forested areas. Zoom in and out as needed. You can use the satellite basemap to assist you, but the basis of your collection should be the Landsat image. Remember that the more points you collect, the more the classifier will learn from the information you provide. For now, let’s set a goal to collect 25 points per class. Click </span><strong>Exit</strong><span> next to </span><strong>Point drawing</strong><span>&nbsp;when finished.</span></p>
</li>
<li><span><img src="../images/canvas/Uploaded%20Media/Screenshot%202023-03-03%20at%207.03.14%20AM.png" alt="collected points"   loading="lazy"></span></li>
<li>
<p><span>Repeat the same process for the other classes by creating new layers. Don’t forget to import using the </span><span>FeatureCollection</span><span> option as mentioned above. For the </span><span>developed</span><span> class, collect points over urban areas. For the </span><span>water</span><span> class, collect points over the Ligurian Sea, and also look for other bodies of water, like rivers. For the </span><span>herbaceous</span><span> class, collect points over agricultural fields. Remember to set the “class” property for each class to its corresponding code (see Table above) and click </span><strong>Exit</strong><span> once you finalize collecting points for each class as mentioned above. We will be using the following hexadecimal colors for the other classes: #FF0000 for </span><span>developed</span><span>, #1A11FF for </span><span>water</span><span>, and #D0741E for </span><span>herbaceous</span><span>.&nbsp;</span></p>
</li>
<li><span><img src="../images/canvas/Uploaded%20Media/Screenshot%202023-03-03%20at%207.04.22%20AM.png" alt="click the new layer button"   loading="lazy"></span></li>
<li><span>You should now have four FeatureCollection imports named forest, developed, water, and herbaceous </span></li>
<li><span><img src="../images/canvas/Uploaded%20Media/Screenshot%202023-03-03%20at%207.07.00%20AM.png" alt="Collected Training Samples"   loading="lazy"></span></li>
<li>
<span><span>&nbsp;</span></span><span>The next step is to combine all the training feature collections into one. Copy and paste the code below to combine them into one </span><span>FeatureCollection</span><span> called </span><span>trainingFeatures</span><span>. Here, we use the </span><span>flatten</span><span> method to avoid having a collection of feature collections—we want individual features within our </span><span>FeatureCollection</span><span>.</span>
</li>
<li>
<pre><span>// Combine training feature collections.<br>var trainingFeatures = ee.FeatureCollection([<br>&nbsp; &nbsp; forest, developed, water, herbaceous<br>]).flatten();&nbsp;</span></pre>
</li>
<li>
<p><span>Note: Alternatively, you could use an existing set of reference data. For example, the European Space Agency (ESA) WorldCover dataset is a global map of land use and land cover derived from ESA’s Sentinel-2 imagery at 10 m resolution. With existing datasets, we can randomly place points on pixels classified as the classes of interest (if you are curious, you can explore the Earth Engine documentation to learn about the </span><span>ee</span><span>.</span><span>Image.stratifiedSample</span><span> and the </span><span>ee</span><span>.</span><span>FeatureCollection.randomPoints</span><span> methods). The drawback is that these global datasets will not always contain the specific classes of interest for your region, or may not be entirely accurate at the local scale. Another option is to use samples collected in the field (e.g., GPS points).</span></p>
</li>
<li>
<p><span>In the combined </span><span>FeatureCollection</span><span>, each </span><span>Feature</span><span> point should have a property called “class”. The class values are consecutive integers from 0 to 3. Verify that this is true by printing </span><span>trainingFeatures</span><span> and checking the properties of the features in the console.</span></p>
</li>
<li>
<p>&nbsp;</p>
<pre><span>&nbsp;print(trainingFeatures);</span></pre>
</li>
<li>
<p><span>Now that we have our training points, copy and paste the code below to extract the band information for each class at each point location.</span></p>
</li>
<li>
<pre>// Define prediction bands.<br>var predictionBands = [<br>&nbsp; &nbsp; 'SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7',<br>&nbsp; &nbsp; 'ST_B10'<br>];<br><br>// Sample training points.<br>var classifierTraining = landsat.select(predictionBands)<br>&nbsp; &nbsp; .sampleRegions({<br>&nbsp; &nbsp; &nbsp; &nbsp; collection: trainingFeatures,<br>&nbsp; &nbsp; &nbsp; &nbsp; properties: ['class'],<br>&nbsp; &nbsp; &nbsp; &nbsp; scale: 30<br>&nbsp; &nbsp; });</pre>
</li>
<li>
<p><span>First, we define the prediction bands to extract different spectral and thermal information from different bands for each class. Then, we use the </span><span>sampleRegions</span><span> method to sample the information from the Landsat image at each point location. This method requires information about the </span><span>FeatureCollection</span><span> (our reference points), the property to extract (“class”), and the pixel scale (in meters).</span></p>
</li>
<li><span>You can check whether the classifierTraining object extracted the properties of interest by printing it and expanding the first feature. You should see the band and class information</span></li>
<li>
<pre><span>print(classifierTraining);</span></pre>
</li>
<li><span><img src="../images/canvas/Uploaded%20Media/Screenshot%202023-03-03%20at%208.43.08%20AM.png" alt="Screenshot 2023-03-03 at 8.43.08 AM.png" loading="lazy"></span></li>
<li><span>Now we can choose a classifier. The choice of classifier is not always obvious, and there are many options from which to pick—you can quickly expand the ee.Classifier object under Docs to get an idea of how many options we have for image classification. Therefore, we will be testing different classifiers and comparing their results. We will start with a Classification and Regression Tree (CART) classifier, a well-known classification algorithm that has been around for decades.&nbsp;</span></li>
<li><span><img src="../images/canvas/Uploaded%20Media/Screenshot%202023-03-03%20at%208.44.22%20AM.png" alt="Example of a decision tree for satellite image classification. Values and classes are hypothetical." loading="lazy"></span></li>
<li><span>The figure above is an example of a decision tree for satellite image classification. Values and classes are hypothetical.</span></li>
<li><span>Copy and paste the code below to instantiate a CART classifier (ee.Classifier.smileCart) and train it.</span></li>
<li>
<pre>//////////////// CART Classifier ///////////////////<br><br>// Train a CART Classifier.<br>var classifier = ee.Classifier.smileCart().train({<br>&nbsp; &nbsp; features: classifierTraining,<br>&nbsp; &nbsp; classProperty: 'class',<br>&nbsp; &nbsp; inputProperties: predictionBands<br>});</pre>
</li>
<li>
<p><span>Essentially, the classifier contains the mathematical rules that link labels to spectral information. If you print the variable </span><span>classifier</span><span> and expand its properties, you can confirm the basic characteristics of the object (bands, properties, and classifier being used). </span></p>
</li>
<li>
<p><span>If you print </span><span>classifier.</span><span>explain</span><span>, you can find a property called “tree” that contains the decision rules.</span></p>
</li>
<li>
<pre><span>print(classifier.explain());</span></pre>
</li>
<li>
<p><img src="../images/canvas/Uploaded%20Media/Screenshot%202023-03-03%20at%208.48.47%20AM.png" alt="print(classifier.explain());" loading="lazy"></p>
</li>
<li>
<p><span>After training the classifier, copy and paste the code below to classify the Landsat image and add it to the </span><strong>Map</strong><span>.</span></p>
</li>
<li>
<pre>// Classify the Landsat image.<br>var classified = landsat.select(predictionBands).classify(classifier);<br><br>// Define classification image visualization parameters.<br>var classificationVis = {<br>&nbsp; &nbsp; min: 0,<br>&nbsp; &nbsp; max: 3,<br>&nbsp; &nbsp; palette: ['589400', 'ff0000', '1a11ff', 'd0741e']<br>};<br><br>// Add the classified image to the map.<br>Map.addLayer(classified, classificationVis, 'CART classified');</pre>
</li>
<li>
<p><span>Note that, in the visualization parameters, we define a </span><span>palette</span><span> parameter which in this case represents colors for each pixel value (0–3, our class codes). We use the same hexadecimal colors used when creating our training points for each class. This way, we can associate a color with a class when visualizing the classified image in the </span><strong>Map</strong><span>.</span></p>
</li>
<li><span><img src="../images/canvas/Uploaded%20Media/Screenshot%202023-03-03%20at%208.51.09%20AM.png" alt="results of CART classifcation" loading="lazy"></span></li>
<li>
<span>Inspect the result: Activate the Landsat composite layer and the satellite basemap to overlay with the classified images (Fig. F2.1.11). Change the layers’ transparency to inspect some areas. What do you notice? The result might not look very satisfactory in some areas (e.g., confusion between </span><span>developed</span><span> and </span><span>herbaceous</span><span> classes). Why do you think this is happening? There are a few options to handle misclassification errors:</span>
<ol style="list-style-type: decimal;">
<li>
<strong>Collect more training data</strong><span> We can try incorporating more points to have a more representative sample of the classes.</span>
</li>
<li>
<strong>Tune the model</strong><span> Classifiers typically have “hyperparameters,” which are set to default values. In the case of classification trees, there are ways to tune the number of leaves in the tree, for example.&nbsp;</span>
</li>
<li>
<strong>Try other classifiers</strong><span> If a classifier’s results are unsatisfying, we can try some of the other classifiers in Earth Engine to see if the result is better or different.</span>
</li>
<li>
<strong>Expand the collection location</strong><span> It is good practice to collect points across the entire image and not just focus on one location. Also, look for pixels of the same class that show variability (e.g., for the </span><span>developed</span><span> class, building rooftops look different than house rooftops; for the </span><span>herbaceous</span><span> class, crop fields show distinctive seasonality/phenology).&nbsp;</span>
</li>
<li>
<strong>Add more predictors</strong><span> We can try adding spectral indices to the input variables; this way, we are feeding the classifier new, unique information about each class. For example, there is a good chance that a vegetation index specialized for detecting vegetation health (e.g., NDVI) would improve the </span><span>developed</span><span> versus </span><span>herbaceous</span><span> classification.</span>
</li>
</ol>
</li>
<li>
<p><span>For now, we will try another supervised learning classifier that is widely used: Random Forests (RF). The RF algorithm (Breiman 2001, Pal 2005) builds on the concept of decision trees, but adds strategies to make them more powerful. It is called a “forest” because it operates by constructing a multitude of decision trees. As mentioned previously, a decision tree creates the rules which are used to make decisions. A Random Forest will randomly choose features and make observations, build a forest of decision trees, and then use the full set of trees to estimate the class. It is a great choice when you do not have a lot of insight about the training data.</span></p>
</li>
<li><span><img src="../images/canvas/Uploaded%20Media/Screenshot%202023-03-03%20at%208.53.56%20AM.png" alt="diagram of Random Forest" loading="lazy"></span></li>
<li>
<p><span>Copy and paste the code below to train the RF classifier (</span><span>ee</span><span>.</span><span>Classifier.smileRandomForest</span><span>) and apply the classifier to the image. The RF algorithm requires, as its argument, the number of trees to build. We will use 50 trees.</span></p>
</li>
<li>
<pre>/////////////// Random Forest Classifier /////////////////////<br><br>// Train RF classifier.<br>var RFclassifier = ee.Classifier.smileRandomForest(50).train({<br>&nbsp; &nbsp; features: classifierTraining,<br>&nbsp; &nbsp; classProperty: 'class',<br>&nbsp; &nbsp; inputProperties: predictionBands<br>});<br><br>// Classify Landsat image.<br>var RFclassified = landsat.select(predictionBands).classify(<br>&nbsp; &nbsp; RFclassifier);<br><br>// Add classified image to the map.<br>Map.addLayer(RFclassified, classificationVis, 'RF classified');</pre>
</li>
<li>
<p><span>Note that in the </span><span>ee</span><span>.</span><span>Classifier.smileRandomForest</span><span> documentation (</span><strong>Docs</strong><span> tab), there is a </span><span>seed</span><span> (random number) parameter. Setting a </span><span>seed</span><span> allows you to exactly replicate your model each time you run it. Any number is acceptable as a seed.</span></p>
</li>
<li><span><img src="../images/canvas/Uploaded%20Media/Screenshot%202023-03-03%20at%208.56.05%20AM.png" alt="results of random forest" loading="lazy"></span></li>
<li>
<p>Inspect the result. How does this classified image differ from the CART one? Is the classifications better or worse? Zoom in and out and change the transparency of layers as needed.</p>
</li>
<li>For Submission, submit a URL with your Code.&nbsp; At the End of your code, as a Comment, answer the following questions.
<ol style="list-style-type: decimal;">
<li>How does this classified image differ from the Random Forest to the CART one?</li>
<li>Why do you think that CART classification had classification errors and in what way would you have improved the classification while still using CART?</li>
<li>Is there a better classification between two of these two methods, explain through visual examination of the images?&nbsp;</li>
</ol>
</li>
</ol>
<p>&nbsp;</p>
            <section id="submission">
                <div class="submission-box">
                    <h3>Lab Submission</h3>
                    <p>Submit lab via email.</p>
                    <p><strong>Subject:</strong> <code>Lab 11 - Supervised Classification - [Your Name]</code></p>
                </div>
            </section>
        </main>

        <footer>
            <p><a href='lab-10-challenge-mapping-urban.html'>&larr; Previous Lab</a> | <a href='lab-12-unsupervised-classification.html'>Next Lab &rarr;</a></p>
            <p><a href="../index.html">&larr; Back to Course Home</a></p>
        </footer>
    </div>
    
</body>
</html>

